Multiple distributions found for package optimum. Picked distribution: optimum-quanto
/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_attentions` is. When `return_dict_in_generate` is not `True`, `output_attentions` is ignored.
  warnings.warn(
/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:818: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.
  warnings.warn(
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 4/4 [00:00<00:00,  4.10it/s]
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 44.17it/s]
Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.46it/s]
Loading pipeline components...: 100%|███████████████████████████████████████████████████| 11/11 [00:23<00:00,  2.16s/it]
LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
100%|███████████████████████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.89it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.90it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.89it/s]
INFO - No device specified. Using best available device: 'cuda'
INFO - Verifying Pruna token.
INFO - Starting cacher auto...
INFO - cacher auto was applied successfully.
100%|███████████████████████████████████████████████████████████████████████████████████| 28/28 [00:05<00:00,  4.80it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 28/28 [00:05<00:00,  4.82it/s]
100%|███████████████████████████████████████████████████████████████████████████████████| 28/28 [00:05<00:00,  4.80it/s]
